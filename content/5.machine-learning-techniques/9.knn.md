---
title: "9. K Nearest Neighbors"
description: "A simple classification algorithm that classifies samples based on their nearest neighbors' classes."
head.image: "/neko.png"
date: "2022-05-29"
---

# Experiment 9 - K Nearest Neighbors

| Experiment | 9                                                          |
| ---------- | ---------------------------------------------------------- |
| Title      | K Nearest Neighbors to classify Iris dataset               |
| Dataset    | https://eec-aids-archive.netlify.app/datasets/mlt/iris.csv |

## Algorithm
- Store all training samples.
- For each testing sample,
  - Calculate the euclidean distance between the current sample and all points in the training set.
  - Get the first `k` points with the shortest distance from the current sample.
  - Assume the current sample's class to be the most frequent class among the `k` neighbors.

## Program

- Download the dataset from the link above.

- Import CSV reader.
  ```py
  # Import CSV Reader
  import csv
  # Import rng
  import random
  ```
- Read data from the CSV file.
  ```py
  data = []
  with open('iris.csv', 'r') as csvfile:
      reader = csv.reader(csvfile)
      for row in reader:
          data.append(row)
  ```
- The dataset has `num_attributes + 1` columns with the last column being the
  label (`setosa` / `versicolor` / `virginica`).
  ```py
  num_attributes = len(data[0][:-1])
  ```
- Convert attribute values into numbers.
  ```py
  for row in data:
    for col in range(0, num_attributes):
      row[col] = float(row[col])
  ```
- Split the dataset into training and testing.
  ```py
  training = []
  testing = []

  for row in data:
    if random.random() < 0.7:
      training.append(row)
    else:
      testing.append(row)
  ```
- Euclidean distance can be found with:
  ```py
  def euclideanDistance(p1, p2):
    dist = 0
    for i in range(len(p1) - 1):
      dist += pow(p1[i] - p2[i], 2)
    dist /= len(p1) - 1
    return dist    
  ```
- Write a function to find the `k` nearest neighbors using the above function.
  ```py
  def getNeighbors(space, point, k):
    distances = []
    for i in range(len(space)):
      dist = euclideanDistance(point, space[i])
      distances.append((space[i][-1], dist))
    distances.sort(key = lambda x: x[1])
    return [x[0] for x in distances[:k]]
  ```
- The most frequent class can be found using the following:
  ```py
  def getFrequent(items):
    res = {}
    for item in items:
      if res.get(item):
        res[item] += 1
      else:
        res[item] = 1
    return sorted(res)[0]
  ```
- We can now test our algorithm:
  ```py
  k = 10
  correct = 0
  for sample in testing:
    nearest = getNeighbors(training, sample, k)
    prediction = getFrequent(nearest)
    if prediction == sample[-1]:
      correct += 1
  print("Accuracy: ", correct / len(testing))
  ```
  For our model, the accuracy is:
  ```py
  Accuracy:  0.8363636363636363
  ```